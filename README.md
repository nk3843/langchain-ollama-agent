# ğŸ§  LangChain Ollama Conversational Agent

A modular, production-grade conversational agent built with **LangChain**, **Ollama**, and **Streamlit**. It supports tool-augmented reasoning with DuckDuckGo search, live weather, and current date retrieval.

---

## ğŸš€ Features

- ğŸ” DuckDuckGo-powered web search
- ğŸŒ¦ï¸ Real-time weather via wttr.in
- ğŸ“… Date retrieval
- ğŸ’¬ Context-aware chat with multi-turn memory
- ğŸ§  Thought â†’ Action â†’ Observation trace in sidebar
- ğŸ› ï¸ Modular tool design (easily extendable)
- âš™ï¸ Powered by local Ollama + Mistral
- ğŸ–¥ï¸ Streamlit frontend

---

## ğŸ–¼ï¸ Preview

> Ask things like:

- `Who is Namo?`
- `What is the weather in Redmond today?`
- `What is today's date?`
- `Search for top AI startups in India`

And see the agent's full reasoning trace in the sidebar.

---

## ğŸ§° Prerequisites

- Python 3.8+
- [Ollama](https://ollama.com) installed locally
- `mistral` model downloaded:
  ```bash
  ollama run mistral
  ```

## ğŸ“¦ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/interactive-agent.git
   cd interactive-agent
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Install the package in development mode:
   ```bash
   pip install -e .
   ```

## ğŸš€ Usage

1. Start the Streamlit app:
   ```bash
   streamlit run streamlit_app.py
   ```

2. Open your browser at `http://localhost:8501`

3. Start chatting with the agent!

## ğŸ› ï¸ Development

### Project Structure
```
interactive_agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”œâ”€â”€ prompt.py
â”‚   â”‚   â””â”€â”€ session.py
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ search.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Adding New Tools

1. Create a new tool in `app/tools/`
2. Register it in `app/agent.py`
3. Update the system prompt in `app/core/prompt.py`

### Environment Variables

Create a `.env` file:
```env
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=mistral
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain)
- [Ollama](https://github.com/ollama/ollama)
- [Streamlit](https://github.com/streamlit/streamlit)
