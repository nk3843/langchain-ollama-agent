# ğŸ§  LangChain Ollama Conversational Agent

A modular, production-grade conversational agent built with **LangChain**, **Ollama**, and **Streamlit**. It supports tool-augmented reasoning with DuckDuckGo search, live weather, and current date retrieval.

---

## ğŸš€ Features

- ğŸ” DuckDuckGo-powered web search
- ğŸŒ¦ï¸ Real-time weather via wttr.in
- ğŸ“… Date retrieval
- ğŸ’¬ Context-aware chat with multi-turn memory
- ğŸ§  Thought â†’ Action â†’ Observation trace in sidebar
- ğŸ› ï¸ Modular tool design (easily extendable)
- âš™ï¸ Powered by local Ollama + Mistral
- ğŸ–¥ï¸ Streamlit frontend

---

## ğŸ–¼ï¸ Preview

> Ask things like:

- `Who is Namo?`
- `What is the weather in Redmond today?`
- `What is today's date?`
- `Search for top AI startups in India`

And see the agent's full reasoning trace in the sidebar.

---

## ğŸ§° Prerequisites

- Python 3.8+
- [Ollama](https://ollama.com) installed locally
- `mistral` model downloaded:
  ```bash
  ollama run mistral
  ```

## ğŸ“¦ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/langchain-ollama-agent.git
   cd langchain-ollama-agent
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“š Dependencies

Key dependencies and their versions:
- langchain==0.3.25
- langchain_community==0.3.24
- langchain_core==0.3.64
- langchain_ollama==0.3.3
- Requests==2.32.3
- streamlit
- ollama

## ğŸš€ Usage

1. Start the Streamlit app:
   ```bash
   streamlit run streamlit_app.py
   ```

2. Open your browser at `http://localhost:8501`

3. Start chatting with the agent!

## ğŸ› ï¸ Development

### Project Structure
```
langchain-ollama-agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ session_manager.py
â”œâ”€â”€ __init__.py
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ render.yaml
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### Adding New Tools

1. Create a new tool in `app/tools/`
2. Register it in `app/agent.py`
3. Update the system prompt in `app/core/prompt.py`

The agent is pre-configured using a Python class in app/config.py. No .env file is needed.
# app/config.py

class AgentConfig:
    model_name = "mistral"
    temperature = 0.1
    max_iterations = 5
    host = "http://localhost:11434"
    timeout = 60

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ™ Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain)
- [Ollama](https://github.com/ollama/ollama)
- [Streamlit](https://github.com/streamlit/streamlit)
